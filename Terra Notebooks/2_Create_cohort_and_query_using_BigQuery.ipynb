{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A note about opening notebooks in shared workspaces <a class=\"tocSkip\">\n",
    "\n",
    "Please do not run master copies of notebooks unless you intend to improve the code. As a general rule, it is good to be cautious when editing a notebook in a shared workspace, because you don't want to overwrite the work of your collaborators. Best practices is to test in a cloned workspace or make a duplicate notebook with an easily identifiable name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook overview <a class=\"tocSkip\">\n",
    "    \n",
    "Terra hosts several datasets stored in BigQuery, and this notebook gives an example of how to import BigQuery data into a notebook using the Data Explorer. We will be working with public-access, low coverage 1,000 Genomes Project data. \n",
    "\n",
    "This notebook is the last step in the Terra_Notebook_QuickStart workspace flow:   \n",
    "![Notebooks_QuickStart_flow](https://storage.cloud.google.com/terra-featured-workspaces/QuickStart/Notebook_QuickStart_oval_flow.png)\n",
    "\n",
    "\n",
    "This notebook assumes you have already done the following (using instructions in the [Terra_Notebooks_Quickstart](https://app.terra.bio/#workspaces/fc-product-demo/Terra_Notebooks_Quickstart/notebooks) workspace dashboard):   \n",
    "- Create a data subset (cohort) in the Data Explorer\n",
    "- Export the particpant IDs of the cohort to your cloned workspace data table\n",
    "\n",
    "As you execute the code in the notebook, you'll go through the following steps: \n",
    "\n",
    "1. Set up the notebook virtual environment\n",
    "2. Get the cohort query (participant IDs) into the notebook environment\n",
    "3. Join data from BigQuery table to the participant IDs in the notebook\n",
    "4. Look at a plot of the data\n",
    "5. Gather provenance for reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # What is BigQuery?<a class=\"tocSkip\">\n",
    "\n",
    "> BigQuery is the Google Cloud Storage solution for structured data (like a spreadsheet optimized for quick retieval of particular sections that you access with a \"query\". To learn more, see this five-minute video from Google [here](https://www.youtube.com/watch?v=aupC-Wj7XDY). Many datasets, including the public-access [1,000 Genomes Project](https://www.internationalgenome.org/about), are stored in BigQuery, for anyone to access. \n",
    "\n",
    "> Exporting the cohort in Terra adds a query to the workspace data table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note about cost**    \n",
    "Although you are not paying for the data storage for this public-access dataset, querying the data carries a cost, paid to Google Cloud Storage. In the case of this notebook, it is only a few cents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup\n",
    "\n",
    "> Before moving on to the analysis, you will need to make sure your virtual notebook environment includes basic R packages and libraries. \n",
    "\n",
    "Be sure to run the notebook **`R environment setup`** in this workspace first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install additional R packages\n",
    "\n",
    "Many notebooks reference additional packages and libraries, which you will install in this section.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# The bigrquery package makes it easy to work with data stored in Google BigQuery by allowing you to query \n",
    "# BigQuery tables and retrieve metadata about your projects, datasets, tables, and jobs\n",
    "library(bigrquery)\n",
    "\n",
    "# ggplot2 is a library of integrated plotting functions\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to allow the notebook kernel, which is on a virtual machine, to speak to the workspace, which is mounted to a google bucket.     \n",
    "\n",
    "> **(Optional) technical detail**: The program that does this, called FISS (Firecloud Service Selector), is a Python module that allows API (Application Programming Interface) calls from the notebook to the workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reticulate package translates Python code into R code, so we can use some Python commands in this R notebook\n",
    "library(reticulate)\n",
    "\n",
    "# Update firecloud service selector module that provides API calls \n",
    "# (Application Programming Interface) from the notebook to the workspace\n",
    "# API calls allow two applications to talk to each other\n",
    "system(\"pip install --upgrade firecloud\", intern = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import firecloud service selector modules using reticulate\n",
    "# Reticulate is an an R library that allows python commands to be used in notebooks\n",
    "\n",
    "os <- import(\"os\")\n",
    "firecloud <- import(\"firecloud\")\n",
    "fiss <- import(\"firecloud.fiss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set project globals\n",
    "\n",
    "> These next few cells set global variables, like the workspace name, automatically. This way, the notebook can be used in multiple workspaces with different project names and users without any manual adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project variables\n",
    "\n",
    "PROJECT <- Sys.getenv('GOOGLE_PROJECT')\n",
    "WORKSPACE <- os$path$basename(os$path$dirname(os$getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project id of the clould project to bill for queries to BigQuery\n",
    "\n",
    "BILLING_PROJECT_ID <- Sys.getenv('GOOGLE_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use access BigQuery, you must first autheniticate, or verify your identity.\n",
    "# This code cell does that. \n",
    "\n",
    "bigrquery::set_service_token(Ronaldo::getServiceAccountKey())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the cohort query\n",
    "\n",
    "> In this section, we are going to pull information from the \"cohort\" table that we created at the beginning of this exercisefrom into the notebook environment. We will use the workspace variables and a program called FISS (Firecloud Service Selector) to accomplish this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The FISS module that communicates between the notebook environment and Terra is in Python, so the first step is to \n",
    "# create Python versions of the workspace and project variables\n",
    "\n",
    "workspace = r_to_py(WORKSPACE)\n",
    "project = r_to_py(PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bring information from the \"cohort\" table into a notebook variable for the name of the table, \"cohort_entity\".\n",
    "cohort_entity<- fiss$fapi$get_entities(project,workspace,\"cohort\")$json()\n",
    "\n",
    "# Look at the first row in the table, finds the column with the header \"query\" and saves this information \n",
    "# as a variable \"cohort_query\"     \n",
    "cohort_query <- cohort_entity[[1]][['attributes']][['query']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sanity check - This cell just prints out information, including the SQL query the notebook will use\n",
    "\n",
    "cohort_entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get an error when running the cell, try rerunning..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note about selecting from multiple workspace cohorts\n",
    "\n",
    "> The command you just ran grabs the first cohort in your workspace data table. If there were multiple queries saved into your workspace table, the one you choose can be changed by updating the number in the double brackets in the code cell above.   \n",
    "\n",
    "> For example, using [[2]] would point to the cohort in the second row of the table.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query and return all results into an in-memory table, \"t\", in R\n",
    "\n",
    "t <- bigrquery::bq_project_query(\n",
    "    BILLING_PROJECT_ID,\n",
    "    cohort_query\n",
    ")\n",
    "tt <- bigrquery::bq_table_download(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the output. This is a table of the participant IDs of your cohort. \n",
    "\n",
    "print(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add data by \"joining\" with another table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The query you just did returns **just the participant IDs** in a table. To do an analysis, you will want additional information from the BigQuery dataset. This section is an example of how to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the public-access data to grab pairs of participants IDs and Genders and put in a table (named \"table\") \n",
    "query <- '\n",
    "SELECT\n",
    "    DISTINCT participant_id,\n",
    "    Gender\n",
    "FROM\n",
    "    `verily-public-data.human_genome_variants.1000_genomes_participant_info`\n",
    "'\n",
    "table_data <- bigrquery::bq_project_query(\n",
    "    BILLING_PROJECT_ID,\n",
    "    query\n",
    ")\n",
    "table <- bigrquery::bq_table_download(table_data)\n",
    "dim(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a **new table**, `merged_table`, of the participant ID and Gender pairs for the participants in the cohort\n",
    "merged_table <- merge(x = tt, y = table, by=\"participant_id\", all.x = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check - print out the dimensions of the merged table \n",
    "# It should have two columns and the number of rows = size of your cohort\n",
    "dim(merged_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot\n",
    "> This last section is to confirm that you have the data you expect in your notebook environment. If you were doing an actual analysis, this is where you would include your R or Python analysis code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped <- table(merged_table$Gender)\n",
    "print(grouped)\n",
    "\n",
    "g <- ggplot(merged_table, aes(Gender))\n",
    "g + geom_bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including this information allows you to easly go back and see the details of your notebook environment\n",
    "# Provenance is also recommended as best practices for reproducible research\n",
    "\n",
    "devtools::session_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2019 The Broad Institute, Inc., Verily Life Sciences, LLC All rights reserved.\n",
    "\n",
    "This software may be modified and distributed under the terms of the BSD license. See the LICENSE file for details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "838.976px",
    "left": "21px",
    "top": "470.965px",
    "width": "267.917px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
